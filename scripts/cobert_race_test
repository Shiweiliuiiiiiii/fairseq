#!/bin/bash
#SBATCH --job-name=cobert_race_random_test
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 0-12:00:00
#SBATCH --cpus-per-task=18
#SBATCH -o cobert_race_random_test.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate slak


ROBERTA_PATH=~/project_space/pruning_fails/QA/pretrained_models/roberta.large/model.pt

#IMP
#for ite in 0 1 2 3 4 5 6 7 8 9
#do
#DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
#MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/imp/0.2/checkpoint_best_iter$ite.pt
#PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/imp/0.2/preds_middle_$ite.tsv
#TEST_SPLIT=test
#
#fairseq-validate \
#    $DATA_DIR \
#    --valid-subset $TEST_SPLIT \
#    --path $MODEL_PATH \
#    --batch-size 1 \
#    --task sentence_ranking \
#    --criterion sentence_ranking \
#    --save-predictions $PREDS_OUT
#done

#for ite in 0 1 2 3 4 5 6 7 8 9
#do
#DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
#MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/imp/0.2/checkpoint_best_iter$ite.pt
#PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/imp/0.2/preds_high_$ite.tsv
#TEST_SPLIT=test1
#
#fairseq-validate \
#    $DATA_DIR \
#    --valid-subset $TEST_SPLIT \
#    --path $MODEL_PATH \
#    --batch-size 1 \
#    --task sentence_ranking \
#    --criterion sentence_ranking \
#    --save-predictions $PREDS_OUT
#done


## random test
for sparsity in 0.2 0.36 0.488 0.590 0.672 0.738 0.791 0.8325 0.866 0.893
do
DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/checkpoint_best.pt
PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/preds_middle.tsv
TEST_SPLIT=test

fairseq-validate \
    $DATA_DIR \
    --valid-subset $TEST_SPLIT \
    --path $MODEL_PATH \
    --batch-size 1 \
    --task sentence_ranking \
    --criterion sentence_ranking \
    --save-predictions $PREDS_OUT
done

for sparsity in 0.2 0.36 0.488 0.590 0.672 0.738 0.791 0.8325 0.866 0.893
do
DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/checkpoint_best.pt
PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/preds_high.tsv
TEST_SPLIT=test1

fairseq-validate \
    $DATA_DIR \
    --valid-subset $TEST_SPLIT \
    --path $MODEL_PATH \
    --batch-size 1 \
    --task sentence_ranking \
    --criterion sentence_ranking \
    --save-predictions $PREDS_OUT
done

## gm test
#for sparsity in 0.2 0.36 0.488 0.590 0.672 0.738 0.791 0.8325 0.866 0.893
#do
#DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
#MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/checkpoint_best.pt
#PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/preds_middle.tsv
#TEST_SPLIT=test
#
#fairseq-validate \
#    $DATA_DIR \
#    --valid-subset $TEST_SPLIT \
#    --path $MODEL_PATH \
#    --batch-size 1 \
#    --task sentence_ranking \
#    --criterion sentence_ranking \
#    --save-predictions $PREDS_OUT
#done
#
#for sparsity in 0.2 0.36 0.488 0.590 0.672 0.738 0.791 0.8325 0.866 0.893
#do
#DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
#MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/checkpoint_best.pt
#PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/preds_high.tsv
#TEST_SPLIT=test1
#
#fairseq-validate \
#    $DATA_DIR \
#    --valid-subset $TEST_SPLIT \
#    --path $MODEL_PATH \
#    --batch-size 1 \
#    --task sentence_ranking \
#    --criterion sentence_ranking \
#    --save-predictions $PREDS_OUT
#done
#
##snip
#for sparsity in 0.2 0.36 0.488 0.590 0.672 0.738 0.791 0.8325 0.866 0.893
#do
#DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
#MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/snip/$sparsity/checkpoint_best.pt
#PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/preds_middle.tsv
#TEST_SPLIT=test
#
#fairseq-validate \
#    $DATA_DIR \
#    --valid-subset $TEST_SPLIT \
#    --path $MODEL_PATH \
#    --batch-size 1 \
#    --task sentence_ranking \
#    --criterion sentence_ranking \
#    --save-predictions $PREDS_OUT
#done
#
#for sparsity in 0.2 0.36 0.488 0.590 0.672 0.738 0.791 0.8325 0.866 0.893
#do
#DATA_DIR=/home/sliu/project_space/pruning_fails/QA/robert/race/RACE
#MODEL_PATH=/home/sliu/project_space/pruning_fails/QA/robert/race/snip/$sparsity/checkpoint_best.pt
#PREDS_OUT=/home/sliu/project_space/pruning_fails/QA/robert/race/gm/$sparsity/preds_high.tsv
#TEST_SPLIT=test1
#
#fairseq-validate \
#    $DATA_DIR \
#    --valid-subset $TEST_SPLIT \
#    --path $MODEL_PATH \
#    --batch-size 1 \
#    --task sentence_ranking \
#    --criterion sentence_ranking \
#    --save-predictions $PREDS_OUT
#done



